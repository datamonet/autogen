{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Executors\n",
    "\n",
    "In the last chapter, \n",
    "we used two agents powered by a large language model (LLM) to play a game\n",
    "by exchanging messages.\n",
    "In this chapter, we introduce code executors, which enable agents to not just chat\n",
    "but also\n",
    "to interact with an environment and perform useful computations and take actions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In AutoGen, a code executor is a component that\n",
    "takes input messages (e.g., those containing code blocks), performs execution, and outputs messages\n",
    "with the results.\n",
    "AutoGen provides two types of built-in code executors, one is \n",
    "command line code executor, which runs code in a command line environment\n",
    "such as a UNIX shell, and the other is Jupyter executor, which runs code\n",
    "in an interactive [Jupyter kernel](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels).\n",
    "\n",
    "For each type of executor, AutoGen provides two ways to execute code: locally and in a Docker container.\n",
    "One way is to execute\n",
    "code directly in the same host platform where AutoGen is running, i.e.,\n",
    "the local operating system.\n",
    "It is for development and testing, but it is not ideal for production\n",
    "as LLM can generate arbitrary code.\n",
    "The other way is to execute code in a Docker container.\n",
    "The table below shows the combinations of code executors and execution\n",
    "environments.\n",
    "\n",
    "| Code Executor (`autogen.coding`) | Environment | Platform |\n",
    "| ---------------------------- | ----------- | -------- |\n",
    "| [`LocalCommandLineCodeExecutor`](/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor)  | Shell       | Local  |\n",
    "| [`DockerCommandLineCodeExecutor`](/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor) | Shell       | Docker |\n",
    "| [`jupyter.JupyterCodeExecutor`](/docs/reference/coding/jupyter/jupyter_code_executor#jupytercodeexecutor)           | Jupyter Kernel (e.g., python3) | Local/Docker |\n",
    "\n",
    "In this chapter, we will focus on the command line code executors.\n",
    "For the Jupyter code executor, please refer to the topic page for \n",
    "[Jupyter Code Executor](/docs/topics/code-execution/jupyter-code-executor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Execution\n",
    "\n",
    "The figure below shows the architecture of the local command line code executor\n",
    "([`autogen.coding.LocalCommandLineCodeExecutor`](/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor)).\n",
    "\n",
    "````mdx-code-block\n",
    ":::danger\n",
    "Executing LLM-generated code poses a security risk to your host environment.\n",
    ":::\n",
    "````\n",
    "\n",
    "```{=mdx}\n",
    "![Code Executor No Docker](./assets/code-executor-no-docker.png)\n",
    "```\n",
    "\n",
    "Upon receiving a message with a code block, the local command line code executor\n",
    "first writes the code block to a code file, then starts a new subprocess to\n",
    "execute the code file. The executor reads the console output of the \n",
    "code execution and sends it back as a reply message.\n",
    "\n",
    "Here is an example of using the code executor to run a Python\n",
    "code block that prints a random number.\n",
    "First we create an agent with the code executor\n",
    "that uses a temporary directory to store the code files.\n",
    "We specify `human_input_mode=\"ALWAYS\"` to manually validate the safety of the the code being \n",
    "executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import tempfile\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "\n",
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a local command line code executor.\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration.\n",
    "code_executor_agent = ConversableAgent(\n",
    "    \"code_executor_agent\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the local command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this example, we need to make sure the `matplotlib` and `numpy`\n",
    "are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "! pip install -qqq matplotlib numpy"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the agent generate a reply given a message with a Python code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "message_with_code_block = \"\"\"This is a message with code block.\n",
    "The code block is below:\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.random.randint(0, 100, 100)\n",
    "y = np.random.randint(0, 100, 100)\n",
    "plt.scatter(x, y)\n",
    "plt.savefig('scatter.png')\n",
    "print('Scatter plot saved to scatter.png')\n",
    "```\n",
    "This is the end of the message.\n",
    "\"\"\"\n",
    "\n",
    "# Generate a reply for the given code.\n",
    "reply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": message_with_code_block}])\n",
    "print(reply)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the generation of response, a human input is requested to give an opportunity\n",
    "to intercept the code execution.\n",
    "In this case, we choose to continue the execution, \n",
    "and the agent's reply contains the output of the code execution.\n",
    "\n",
    "We can take a look at the generated plot in the temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(temp_dir.name))\n",
    "# We can see the output scatter.png and the code file generated by the agent."
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the working directory to avoid affecting future conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "temp_dir.cleanup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Execution\n",
    "\n",
    "To mitigate the security risk of running LLM-generated code locally, \n",
    "we can use the docker command line code executor \n",
    "([`autogen.coding.DockerCommandLineCodeExecutor`](/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor))\n",
    "to execute code in a docker container.\n",
    "This way, the generated code can only access resources that are explicitly \n",
    "given to it.\n",
    "\n",
    "The figure below illustrates how does the docker execution works.\n",
    "\n",
    "```{=mdx}\n",
    "![Code Executor Docker](./assets/code-executor-docker.png)\n",
    "```\n",
    "\n",
    "Similar to the local command line code executor, the docker executor \n",
    "extracts code blocks from input messages, writes them to code files.\n",
    "For each code file, it starts a docker container to execute the code file,\n",
    "and reads the console output of the code execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use docker execution, you need to [install Docker](https://docs.docker.com/engine/install/) on your machine.\n",
    "Once you have Docker installed and running, you can set up your code executor agent as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "from autogen.coding import DockerCommandLineCodeExecutor\n",
    "\n",
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a Docker command line code executor.\n",
    "executor = DockerCommandLineCodeExecutor(\n",
    "    image=\"python:3.12-slim\",  # Execute code using the given docker image name.\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration that uses docker.\n",
    "code_executor_agent_using_docker = ConversableAgent(\n",
    "    \"code_executor_agent_docker\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the docker command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always take human input for this agent for safety.\n",
    ")\n",
    "\n",
    "# When the code executor is no longer used, stop it to release the resources.\n",
    "# executor.stop()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `work_dir` in the constructor points to a local file system directory just like in the local execution case.\n",
    "The docker container will mount this directory and the executor write code files\n",
    "and output to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Code Execution in Conversation\n",
    "\n",
    "Writing and executing code is necessary for many tasks such as \n",
    "data analysis, machine learning, and mathematical modeling.\n",
    "In AutoGen, coding can be a conversation between a code writer agent and a \n",
    "code executor agent, mirroring the interaction between a programmer and a\n",
    "code interpreter.\n",
    "\n",
    "```{=mdx}\n",
    "![Code Writer and Code Executor](./assets/code-execution-in-conversation.png)\n",
    "```\n",
    "\n",
    "The code writer agent can be powered by an LLM such as GPT-4 with code-writing\n",
    "capability.\n",
    "And the code executor agent is powered by a code executor.\n",
    "\n",
    "The following is an agent with a code writer role specified \n",
    "using `system_message`. The system message contains important instruction\n",
    "on how to use the code executor in the code executor agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# The code writer agent's system message is to instruct the LLM on how to use\n",
    "# the code executor in the code executor agent.\n",
    "code_writer_system_message = \"\"\"You are a helpful AI assistant.\n",
    "Solve tasks using your coding and language skills.\n",
    "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
    "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
    "2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
    "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
    "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
    "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
    "Reply 'TERMINATE' in the end when everything is done.\n",
    "\"\"\"\n",
    "\n",
    "code_writer_agent = ConversableAgent(\n",
    "    \"code_writer_agent\",\n",
    "    system_message=code_writer_system_message,\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    code_execution_config=False,  # Turn off code execution for this agent.\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of solving a math problem through a conversation\n",
    "between the code writer agent and the code executor agent (created above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "chat_result = code_executor_agent.initiate_chat(\n",
    "    code_writer_agent,\n",
    "    message=\"Write Python code to calculate the 14th Fibonacci number.\",\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the previous chat session, human input was requested each time\n",
    "the code executor agent responded to ensure that the code was safe to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try a more complex example that involves querying the web.\n",
    "Let's say we want to get the the stock price gains year-to-date for\n",
    "Tesla and Meta (formerly Facebook). We can also use the two agents\n",
    "with several iterations of conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "import datetime\n",
    "\n",
    "today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "chat_result = code_executor_agent.initiate_chat(\n",
    "    code_writer_agent,\n",
    "    message=f\"Today is {today}. Write Python code to plot TSLA's and META's \"\n",
    "    \"stock price gains YTD, and save the plot to a file named 'stock_gains.png'.\",\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous conversation, the code writer agent generated a code block\n",
    "to install necessary packages and another code block for a script to \n",
    "fetch the stock price and calculate gains year-to-date for Tesla and Meta.\n",
    "The code executor agent installed the packages, executed the script, \n",
    "and returned the results.\n",
    "\n",
    "Let's take a look at the chart that was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(os.path.join(temp_dir, \"stock_gains.png\"))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because code execution leave traces like code files and output in the file system, \n",
    "we may want to clean up the working directory after each conversation concludes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "source": [
    "temp_dir.cleanup()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the docker command line executor to clean up the docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "executor.stop()  # Stop the docker command line code executor."
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line or Jupyter Code Executor?\n",
    "\n",
    "The command line code executor does not keep any state in memory between\n",
    "executions of different code blocks it receives, as it writes each code block to\n",
    "a separate file and executes the code block in a new process.\n",
    "\n",
    "Contrast to the command line code executor, the Jupyter code executor\n",
    "runs all code blocks in the same Jupyter kernel, which keeps the state\n",
    "in memory between executions.\n",
    "See the topic page for [Jupyter Code Executor](/docs/topics/code-execution/jupyter-code-executor).\n",
    "\n",
    "The choice between command line and Jupyter code executor depends on the\n",
    "nature of the code blocks in agents' conversation.\n",
    "If each code block is a \"script\" that does not use variables from\n",
    "previous code blocks, the command line code executor is a good choice.\n",
    "If some code blocks contain expensive computations (e.g., training a\n",
    "machine learning model and loading a large amount of data), and you want to\n",
    "keep the state in memory to avoid repeated computations,\n",
    "the Jupyter code executor is a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on User Proxy Agent and Assistant Agent\n",
    "\n",
    "### User Proxy Agent\n",
    "\n",
    "In the previous examples, we create the code executor agent directly using\n",
    "the [`ConversableAgent`](/docs/reference/agentchat/conversable_agent#conversableagent) class. Existing AutoGen examples often create \n",
    "code executor agent using the [`UserProxyAgent`](/docs/reference/agentchat/user_proxy_agent#userproxyagent) class, \n",
    "which is a subclass of\n",
    "[`ConversableAgent`](/docs/reference/agentchat/conversable_agent#conversableagent) with `human_input_mode=ALWAYS` and `llm_config=False` --\n",
    "it always requests human input for every message and does not use LLM.\n",
    "It also comes with default `description` field for each of the\n",
    "`human_input_mode` setting.\n",
    "This class is a convenient short-cut for creating an agent that is\n",
    "intended to be used as a code executor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Assistant Agent\n",
    "\n",
    "In the previous examples, we created the code writer agent directly using\n",
    "the [`ConversableAgent`](/docs/reference/agentchat/conversable_agent#conversableagent) class. Existing AutoGen examples often create the code writer\n",
    "agent using the [`AssistantAgent`](/docs/reference/agentchat/assistant_agent#assistantagent) class, which is a subclass of\n",
    "[`ConversableAgent`](/docs/reference/agentchat/conversable_agent#conversableagent) with `human_input_mode=NEVER` and `code_execution_config=False` \n",
    "-- it never requests human input and does not use code executor.\n",
    "It also comes with default `system_message` and `description` fields.\n",
    "This class is a convenient short-cut for creating an agent that is\n",
    "intended to be used as a code writer and does not execute code.\n",
    "\n",
    "In fact, in the previous example we use the default `system_message` field\n",
    "of the [`AssistantAgent`](/docs/reference/agentchat/assistant_agent#assistantagent) class to instruct the code writer agent how to use\n",
    "code executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "import pprint\n",
    "\n",
    "from autogen import AssistantAgent\n",
    "\n",
    "pprint.pprint(AssistantAgent.DEFAULT_SYSTEM_MESSAGE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practice\n",
    "\n",
    "It is very important to note that the [`UserProxyAgent`](/docs/reference/agentchat/user_proxy_agent#userproxyagent) and [`AssistantAgent`](/docs/reference/agentchat/assistant_agent#assistantagent)\n",
    "are meant to be shortcuts to avoid writing the `system_message` instructions\n",
    "for the [`ConversableAgent`](/docs/reference/agentchat/conversable_agent#conversableagent) class. \n",
    "They are not suitable for all use cases.\n",
    "As we will show in the next chapter, tuning the \n",
    "`system_message` field\n",
    "is vital for agent to work properly in more complex conversation patterns\n",
    "beyond two-agent chat.\n",
    "\n",
    "As a best practice, always tune your agent's `system_message` instructions\n",
    "for your specific use case and avoid subclassing [`UserProxyAgent`](/docs/reference/agentchat/user_proxy_agent#userproxyagent) and\n",
    "[`AssistantAgent`](/docs/reference/agentchat/assistant_agent#assistantagent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this chapter, we introduced code executors, how to set up Docker and local\n",
    "execution, and how to use code execution in a conversation to solve tasks.\n",
    "In the next chapter, we will introduce tool use, which is similar to code\n",
    "executors but restricts what code an agent can execute."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
